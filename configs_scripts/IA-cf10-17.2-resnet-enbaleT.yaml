config:
  run_script_name: train_instability_analysis
  run_script_kwargs:

    main_training_job_dir: /system/user/beck/pwbeck/projects/regularization/tflearning/outputs/IA-A-cifar10-17.2.2-resnet-B--230204_215821
    resume_training_sweep_dir: #/system/user/beck/pwbeck/projects/regularization/tflearning/outputs/IA-B-cifar10-17.2.1-resnet-B--230120_141533
    
    run_config:
      exec_type: parallel
      hostname: dragonfly
      gpu_ids: [0]
      runs_per_gpu: 2
      wandb:
        init:
          tags:
          - ${config.run_script_kwargs.job_config.experiment_data.experiment_tag}_exps
          - run_handler
          notes: null
          group: ${config.run_script_kwargs.job_config.experiment_data.experiment_tag}
          job_type: run_handler

    start_num: 2

    job_config:
      experiment_data:
        entity: fslgroup #jkuiml-fsl
        project_name: tflearning
        experiment_tag: '17.2'
        experiment_type: startnum_${config.run_script_kwargs.start_num}
        experiment_name: cifar10-${config.run_script_kwargs.job_config.experiment_data.experiment_tag}.${config.run_script_kwargs.start_num}-resnet-B
        experiment_dir: null
        experiment_notes: 
        seed: 0
        gpu_id: 1
      wandb:
        init:
          tags:
          - ${config.run_script_kwargs.job_config.experiment_data.experiment_tag}_exps
          notes: ${config.run_script_kwargs.job_config.experiment_data.experiment_notes}
          group: ${config.run_script_kwargs.job_config.experiment_data.experiment_tag}
          job_type: ${config.run_script_kwargs.job_config.experiment_data.experiment_type}

      model:
        model_cfg: resnet20-cifar10-B

      trainer:
        training_setup: supervised
        n_steps: 64e3
        log_train_step_every: 10
        log_additional_logs: true
        val_every: 500
        save_every: 4000
        batch_size: 128
        optimizer_scheduler:
          optimizer_name: SGD
          optimizer_kwargs:
            lr: 0.1
            momentum: 0.9
            weight_decay: 0.0001
          lr_scheduler_name: MultiStepLR
          lr_scheduler_kwargs:
            milestones: [32e3, 48e3]
            gamma: 0.1
        loss: crossentropy
        metrics:
        - Accuracy
        num_workers: 4

      data:
        dataset: cifar10
        dataset_kwargs:
          data_root_path: /system/user/beck/pwbeck/data
        dataset_split:
          train_val_split: 0.9
        train_split_transforms:
          image_transforms:
          - RandomHorizontalFlip
          - RandomCrop:
              size: 32
              padding: 4
          tensor_transforms: 
          joint_tensor_transforms: 
          enable_transforms: True

    # run1
    instability_analysis_config: 
      - score_fn: TError #TAccuracy
        interpolation_factors: [-1.0, -0.8999999761581421, -0.800000011920929, -0.699999988079071, -0.6000000238418579, -0.5, -0.3999999761581421, -0.30000001192092896, -0.19999998807907104, -0.09999998658895493, 1.4901161193847656e-08, 0.10000002384185791, 0.20000001788139343, 0.30000001192092896, 0.40000003576278687, 0.5, 0.5999999642372131, 0.699999988079071, 0.7999999523162842, 0.8999999761581421, 1.0, 1.100000023841858, 1.2000000476837158, 1.2999999523162842, 1.399999976158142, 1.5, 1.600000023841858, 1.7000000476837158, 1.7999999523162842, 1.899999976158142, 2.0]
        interpolate_linear_kwargs: 
          update_bn_statistics: True
        init_model_idxes_ks_or_every: [0,5,10,30,50,100,250,500,1000,2000,5000,10000,15000,20000,30000] # show instability at these checkpoint idxes
        interpolate_at_model_idxes: [-2]
        save_folder_suffix: fine-bnupdateOn-wide

    # run2
      # - score_fn: TError #TAccuracy
      #   interpolation_factors: [-1.0, -0.8999999761581421, -0.800000011920929, -0.699999988079071, -0.6000000238418579, -0.5, -0.3999999761581421, -0.30000001192092896, -0.19999998807907104, -0.09999998658895493, 1.4901161193847656e-08, 0.10000002384185791, 0.20000001788139343, 0.30000001192092896, 0.40000003576278687, 0.5, 0.5999999642372131, 0.699999988079071, 0.7999999523162842, 0.8999999761581421, 1.0, 1.100000023841858, 1.2000000476837158, 1.2999999523162842, 1.399999976158142, 1.5, 1.600000023841858, 1.7000000476837158, 1.7999999523162842, 1.899999976158142, 2.0]
      #   interpolate_linear_kwargs: 
      #     update_bn_statistics: False #True
      #   init_model_idxes_ks_or_every: [0,5,10,30,50,100,250,500,1000,2000,5000,10000,15000,20000,30000] # show instability at these checkpoint idxes
      #   interpolate_at_model_idxes: [-2]
      #   save_folder_suffix: fine-bnupdateOff-wide

    # run3
    # instability_analysis_config: 
    #   score_fn: TAccuracy
    #   interpolation_factors: [-0.1000,  0.0000,  0.1000,  0.3000,  0.5000,  0.7000,  0.9000,  1.0000, 1.1000] #[0.0, 0.25, 0.5, 0.75, 1.0] #
    #   interpolate_linear_kwargs: 
    #     update_bn_statistics: False #True
    #   init_model_idxes_ks_or_every: [0,50,100,250,500,1000,2000,5000,10000,15000] # show instability at these checkpoint idxes
    #   interpolate_at_model_idxes: [-1, -2]
    #   save_folder_suffix: nobn-Acc-1

    # run4
    # instability_analysis_config: 
    #   score_fn: TAccuracy
    #   interpolation_factors: [-0.1000,  0.0000,  0.1000,  0.3000,  0.5000,  0.7000,  0.9000,  1.0000, 1.1000] #[0.0, 0.25, 0.5, 0.75, 1.0] #
    #   interpolate_linear_kwargs: 
    #     update_bn_statistics: True
    #   init_model_idxes_ks_or_every: [0,50,100,250,500,1000,2000,5000,10000,15000] # show instability at these checkpoint idxes
    #   interpolate_at_model_idxes: [-1, -2]
    #   save_folder_suffix: Acc-1