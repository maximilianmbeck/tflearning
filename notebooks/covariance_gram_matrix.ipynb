{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erank(matrix_A):\n",
    "    s = torch.linalg.svdvals(matrix_A)\n",
    "    return torch.exp(torch.distributions.Categorical(probs=s).entropy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating covariance matrices, their spectra and approximation by gram matrices\n",
    "\n",
    "This notebook serves as playground to get a feeling for the approximations used in Appendix C of [#].\n",
    "\n",
    "[#] Jastrzebski, Stanislaw, Maciej Szymczak, Stanislav Fort, Devansh Arpit, Jacek Tabor, Kyunghyun Cho*, and Krzysztof Geras*. 2022. “The Break-Even Point on Optimization Trajectories of Deep Neural Networks.” In . https://openreview.net/forum?id=r1g87C4KwB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 0.5000],\n",
       "        [0.0000, 2.0000, 0.0000],\n",
       "        [3.0000, 0.0000, 1.0000],\n",
       "        [5.0000, 1.5000, 3.5000]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_mat = torch.tensor([[1,0,3.,5.],[1.,2.,0,1.5],[0.5,0,1.,3.5]])\n",
    "a_mat = a_mat.T\n",
    "a_mat # matrix containing gradients in its columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8333],\n",
       "         [0.6667],\n",
       "         [1.3333],\n",
       "         [3.3333]]),\n",
       " 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_samples = a_mat.shape[1]\n",
    "a_mean_vec = a_mat.mean(dim=1, keepdim=True)\n",
    "a_mean_vec, N_samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the covariance matrix and its spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  0.,  3.,  5.],\n",
       "         [ 0.,  0.,  0.,  0.],\n",
       "         [ 3.,  0.,  9., 15.],\n",
       "         [ 5.,  0., 15., 25.]]),\n",
       " tensor([[1., 0., 3., 5.]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to compute the covariance matrix, we average the outer product of each row with itself\n",
    "a_mat[:,0][None] * a_mat[:,0][None].T, a_mat[:,0][None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0556,  0.1111,  0.0556, -0.0278],\n",
       "        [ 0.1111,  0.8889, -0.8889, -1.2222],\n",
       "        [ 0.0556, -0.8889,  1.5556,  1.7222],\n",
       "        [-0.0278, -1.2222,  1.7222,  2.0556]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = 1./N_samples * torch.mm((a_mat-a_mean_vec), (a_mat-a_mean_vec).T)\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0556,  0.1111,  0.0556, -0.0278],\n",
       "        [ 0.1111,  0.8889, -0.8889, -1.2222],\n",
       "        [ 0.0556, -0.8889,  1.5556,  1.7222],\n",
       "        [-0.0278, -1.2222,  1.7222,  2.0556]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov0 = torch.cov(a_mat, correction=0) # this is the same as the above\n",
    "cov0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0833,  0.1667,  0.0833, -0.0417],\n",
       "        [ 0.1667,  1.3333, -1.3333, -1.8333],\n",
       "        [ 0.0833, -1.3333,  2.3333,  2.5833],\n",
       "        [-0.0417, -1.8333,  2.5833,  3.0833]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# typically we use the correction=1, which returns an unbiased estimate of the covariance matrix\n",
    "cov1 = torch.cov(a_mat, correction=1)\n",
    "cov1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the spectrum of the Covariance matrix\n",
    "From the book \"Mathematics for Machine Learning\" we know that the SVD of a symmetric, positive definite matrix (SPD matrix) is their eigendecomposition. \n",
    "The covariance matrix is a SPD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.3395762e+00, 4.9375668e-01, 9.2944150e-09, 5.7240874e-09],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.svd(cov1.numpy(), compute_uv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.3395762e+00,  4.9375668e-01,  9.2944150e-09, -5.7240874e-09],\n",
       "       dtype=float32),\n",
       " array([[ 0.00780286, -0.4098687 , -0.9120492 ,  0.01063228],\n",
       "        [ 0.41184884, -0.7228833 ,  0.33355078,  0.4433556 ],\n",
       "        [-0.58656186, -0.55515   ,  0.23817348, -0.5394693 ],\n",
       "        [-0.6973269 ,  0.03543959, -0.01354827,  0.7157483 ]],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eig(cov1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.linalg_eig(\n",
       "eigenvalues=tensor([ 2.9802e-08+0.j,  4.9376e-01+0.j,  6.3396e+00+0.j, -1.5220e-07+0.j]),\n",
       "eigenvectors=tensor([[ 0.9121+0.j, -0.4099+0.j,  0.0078+0.j, -0.2006+0.j],\n",
       "        [-0.3284+0.j, -0.7229+0.j,  0.4118+0.j,  0.5085+0.j],\n",
       "        [-0.2444+0.j, -0.5551+0.j, -0.5866+0.j, -0.4697+0.j],\n",
       "        [ 0.0219+0.j,  0.0354+0.j, -0.6973+0.j,  0.6932+0.j]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.eig(cov1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.9802e-08+0.j,  4.9376e-01+0.j,  6.3396e+00+0.j, -1.5220e-07+0.j])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.eigvals(cov1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.linalg_eigh(\n",
       "eigenvalues=tensor([4.1940e-07, 4.8632e-07, 4.9376e-01, 6.3396e+00]),\n",
       "eigenvectors=tensor([[-0.3435,  0.8450,  0.4099, -0.0078],\n",
       "        [-0.2906, -0.4726,  0.7229, -0.4118],\n",
       "        [ 0.5892, -0.0244,  0.5551,  0.5866],\n",
       "        [-0.6711, -0.2492, -0.0354,  0.6973]]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.eigh(cov1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.7678e-08,  4.2999e-07,  4.9376e-01,  6.3396e+00])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.eigvalsh(cov1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.linalg_svd(\n",
       "U=tensor([[-0.0078,  0.4099,  0.9030,  0.1285],\n",
       "        [-0.4118,  0.7229, -0.3881,  0.3965],\n",
       "        [ 0.5866,  0.5552, -0.1664, -0.5657],\n",
       "        [ 0.6973, -0.0354, -0.0791,  0.7115]]),\n",
       "S=tensor([6.3396e+00, 4.9376e-01, 1.4350e-07, 4.6954e-08]),\n",
       "Vh=tensor([[-0.0078, -0.4118,  0.5866,  0.6973],\n",
       "        [ 0.4099,  0.7229,  0.5552, -0.0354],\n",
       "        [ 0.2290, -0.5153,  0.4581, -0.6871],\n",
       "        [ 0.8829, -0.2055, -0.3714,  0.2009]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.svd(cov1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.3396e+00, 4.9376e-01, 1.4350e-07, 4.6954e-08])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.svdvals(cov1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**:\n",
    "I will use torch.linalg.svdvals(cov) to compute the spectrum of the covariance matrix. \n",
    "\n",
    "**Question**: I do not know why torch.linalg.eigvals != torch.linalg.svdvals in this case? For numpy this is almost the same! Differences occur only at the smaller eigenvalues close to zero.\n",
    "\n",
    "Probable cause: Differences in numerical implementation of the algorithms. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Gram matrix\n",
    "\n",
    "$\\mathbf{K}^M$, with entries estimated by $L$ mini-batch gradients $g_i$:\n",
    "$$\\mathbf{K}^M_{ij} = \\frac{1}{L} \\langle g_i-\\hat{g}, g_j- \\hat{g} \\rangle $$\n",
    "where $\\hat{g}$ is the mean of all $L$ gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covariance_gram_matrix(input_matrix, correction=0):\n",
    "    # input_matrix: rows are variables and columns are observations\n",
    "    N_samples = input_matrix.shape[1]\n",
    "    N_samples = input_matrix.shape[1]\n",
    "    mean = input_matrix.mean(dim=1, keepdim=False)\n",
    "    gram_matrix = torch.zeros((N_samples, N_samples))\n",
    "    for i in range(N_samples):\n",
    "        for j in range(i+1):\n",
    "            gram_matrix[i,j] = gram_matrix[j,i] = torch.dot(input_matrix[:,i]-mean, input_matrix[:,j]-mean)\n",
    "    return gram_matrix/(N_samples-correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0093, -2.0463,  0.0370],\n",
       "        [-2.0463,  2.3148, -0.2685],\n",
       "        [ 0.0370, -0.2685,  0.2315]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_gram = compute_covariance_gram_matrix(a_mat)\n",
    "cov_gram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gram matrix computation impls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 0.5000],\n",
       "        [0.0000, 2.0000, 0.0000],\n",
       "        [3.0000, 0.0000, 1.0000],\n",
       "        [5.0000, 1.5000, 3.5000]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try 1 \n",
    "input_matrix = a_mat\n",
    "N_samples = input_matrix.shape[1]\n",
    "mean = input_matrix.mean(dim=1, keepdim=False)\n",
    "gram_matrix = torch.zeros((N_samples, N_samples))\n",
    "for i in range(N_samples):\n",
    "    for j in range(N_samples):\n",
    "        gram_matrix[i,j] = torch.dot(input_matrix[:,i]-mean, input_matrix[:,j]-mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0278, -6.1389,  0.1111],\n",
       "        [-6.1389,  6.9444, -0.8056],\n",
       "        [ 0.1111, -0.8056,  0.6944]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try 2\n",
    "input_matrix = a_mat\n",
    "N_samples = input_matrix.shape[1]\n",
    "mean = input_matrix.mean(dim=1, keepdim=False)\n",
    "gram_matrix = torch.zeros((N_samples, N_samples))\n",
    "for i in range(N_samples):\n",
    "    for j in range(i+1):\n",
    "        gram_matrix[i,j] = gram_matrix[j,i] = torch.dot(input_matrix[:,i]-mean, input_matrix[:,j]-mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0093, -2.0463,  0.0370],\n",
       "        [-2.0463,  2.3148, -0.2685],\n",
       "        [ 0.0370, -0.2685,  0.2315]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_matrix / N_samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrum of the gram matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_gram0 = compute_covariance_gram_matrix(a_mat, correction=0)\n",
    "cov_gram1 = compute_covariance_gram_matrix(a_mat, correction=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.0093, -2.0463,  0.0370],\n",
       "         [-2.0463,  2.3148, -0.2685],\n",
       "         [ 0.0370, -0.2685,  0.2315]]),\n",
       " tensor([[ 0.0556,  0.1111,  0.0556, -0.0278],\n",
       "         [ 0.1111,  0.8889, -0.8889, -1.2222],\n",
       "         [ 0.0556, -0.8889,  1.5556,  1.7222],\n",
       "         [-0.0278, -1.2222,  1.7222,  2.0556]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_gram0, cov0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4.2264e+00, 3.2917e-01, 5.4963e-08]),\n",
       " tensor([6.3396e+00, 4.9376e-01, 3.7755e-07]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.svdvals(cov_gram0), torch.linalg.svdvals(cov_gram1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4.2264e+00, 3.2917e-01, 7.4244e-08, 6.5520e-09]),\n",
       " tensor([6.3396e+00, 4.9376e-01, 1.4350e-07, 4.6954e-08]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.svdvals(cov0), torch.linalg.svdvals(cov1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULT**: The spectra of the covariance and the covariance matrix are identical in their first (common) components!\n",
    "Can we prove this?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger scale study of the spectra of Covariance and Covariance Gram matrix on random matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dim = 100\n",
    "num_vecs = 10\n",
    "correction = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_mat = torch.randn((num_dim, num_vecs))\n",
    "cov = torch.cov(a_mat, correction=correction)\n",
    "cov_gram = compute_covariance_gram_matrix(a_mat, correction=correction)\n",
    "cov_svdvals = torch.linalg.svdvals(cov)\n",
    "cov_gram_svdvals = torch.linalg.svdvals(cov_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.7374e+01, 1.5187e+01, 1.2275e+01, 1.1412e+01, 1.0999e+01, 1.0189e+01,\n",
       "         9.5155e+00, 7.5817e+00, 5.9574e+00, 4.4973e-06]),\n",
       " tensor([1.7374e+01, 1.5187e+01, 1.2275e+01, 1.1412e+01, 1.0999e+01, 1.0189e+01,\n",
       "         9.5155e+00, 7.5817e+00, 5.9574e+00, 2.1092e-07]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_svdvals[:len(cov_gram_svdvals)], cov_gram_svdvals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULT**: They are identical also for large random matrices! This must be provable!\n",
    "I will use this computation to estimate the condition number and largest eigenvalue of the covariance matrix. \n",
    "\n",
    "**Question**: Is there also a relation between the eigenvectors of the covariance and the covariance gram matrix? This would have an implication on our SubGD method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the erank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_distr1 = torch.distributions.Categorical(probs=cov_gram_svdvals)\n",
    "# this is wrong:\n",
    "svd_distr2 = torch.distributions.Categorical(logits=cov_gram_svdvals)\n",
    "# logits are take the log of the probabilities, so they are not the same\n",
    "# However, we can use the log of the probabilities:\n",
    "svd_distr3 = torch.distributions.Categorical(logits=torch.log(cov_gram_svdvals))\n",
    "# and then it would be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.1528), tensor(0.3943), tensor(2.1528))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_distr1.entropy(), svd_distr2.entropy(), svd_distr3.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.7289e-01, 1.5113e-01, 1.2215e-01, 1.1356e-01, 1.0945e-01, 1.0140e-01,\n",
       "         9.4688e-02, 7.5446e-02, 5.9282e-02, 2.0989e-09]),\n",
       " tensor([8.8983e-01, 9.9860e-02, 5.4298e-03, 2.2906e-03, 1.5153e-03, 6.7438e-04,\n",
       "         3.4370e-04, 4.9703e-05, 9.7938e-06, 2.5332e-08]),\n",
       " tensor([1.7289e-01, 1.5113e-01, 1.2215e-01, 1.1356e-01, 1.0945e-01, 1.0140e-01,\n",
       "         9.4688e-02, 7.5446e-02, 5.9282e-02, 2.0989e-09]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_distr1.probs, svd_distr2.probs, svd_distr3.probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.6086)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(svd_distr1.entropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8.6087), tensor(8.6086))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erank(cov), erank(cov_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subspaces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac019f01eb2a0970f066d5e193a84f30bb43215eeeface9d3d8db32241c79700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
