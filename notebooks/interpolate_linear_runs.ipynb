{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "# mycode\n",
    "from ml_utilities.output_loader.result_loader import SweepResult, JobResult\n",
    "from tflearning.mode_connectivity.linear_interpolation import interpolate_linear_runs\n",
    "from ml_utilities.torch_utils.metrics import TError\n",
    "from ml_utilities.data.datasetgenerator import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_train_step</th>\n",
       "      <th>best_val_score</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IA-A-cifar10-17.2.1-resnet-B--230120_134950</th>\n",
       "      <td>44500</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             best_train_step  best_val_score  \\\n",
       "IA-A-cifar10-17.2.1-resnet-B--230120_134950            44500          0.9166   \n",
       "\n",
       "                                             seed  \n",
       "IA-A-cifar10-17.2.1-resnet-B--230120_134950     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_0 = JobResult('/system/user/beck/pwbeck/projects/regularization/tflearning/outputs/IA-A-cifar10-17.2.1-resnet-B--230120_134950')\n",
    "run_0.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_0.get_data_log('val')['Accuracy'].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_step      89449.000000\n",
       "loss              0.371612\n",
       "Accuracy          0.916600\n",
       "epoch           127.000000\n",
       "train_step    44500.000000\n",
       "Name: 89, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_0.get_data_log('val').iloc[89,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(run_0.get_data_log('val').style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_train_step</th>\n",
       "      <th>best_val_score</th>\n",
       "      <th>trainer.resume_training.checkpoint_idx</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IA-B-cifar10-17.2.1-resnet-B--checkpoint_idx-0-seed-1--230120_161833</th>\n",
       "      <td>64000</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    best_train_step  \\\n",
       "IA-B-cifar10-17.2.1-resnet-B--checkpoint_idx-0-...            64000   \n",
       "\n",
       "                                                    best_val_score  \\\n",
       "IA-B-cifar10-17.2.1-resnet-B--checkpoint_idx-0-...          0.9134   \n",
       "\n",
       "                                                    trainer.resume_training.checkpoint_idx  \\\n",
       "IA-B-cifar10-17.2.1-resnet-B--checkpoint_idx-0-...                                       0   \n",
       "\n",
       "                                                    seed  \n",
       "IA-B-cifar10-17.2.1-resnet-B--checkpoint_idx-0-...     1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_1 = JobResult('/system/user/beck/pwbeck/projects/regularization/tflearning/outputs/IA-B-cifar10-17.2.1-resnet-B--230120_141533/outputs/IA-B-cifar10-17.2.1-resnet-B--checkpoint_idx-0-seed-1--230120_161833')\n",
    "run_1.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cfg = \"\"\"\n",
    "data:\n",
    "  dataset: cifar10\n",
    "  dataset_kwargs:\n",
    "    data_root_path: /system/user/beck/pwbeck/data\n",
    "  dataset_split:\n",
    "    train_val_split: 0.9\n",
    "    restrict_n_samples_train_task: 10000\n",
    "  # train_split_transforms:\n",
    "    # image_transforms:\n",
    "    # - RandomHorizontalFlip\n",
    "    # - RandomCrop:\n",
    "    #     size: 32\n",
    "    #     padding: 4\n",
    "    # tensor_transforms: \n",
    "    # joint_tensor_transforms: \n",
    "    # enable_transforms: True\n",
    "\"\"\"\n",
    "data_cfg = OmegaConf.create(data_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "datagen = DatasetGenerator(**data_cfg.data)\n",
    "datagen.generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret = interpolate_linear_runs(run_0, run_1, score_fn=TError(), model_idx=[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphas:  50%|█████     | 1/2 [01:30<01:30, 90.43s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/system/user/beck/pwbeck/projects/regularization/tflearning/notebooks/interpolate_linear_runs.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdragonfly/system/user/beck/pwbeck/projects/regularization/tflearning/notebooks/interpolate_linear_runs.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ret \u001b[39m=\u001b[39m interpolate_linear_runs(run_0, run_1, score_fn\u001b[39m=\u001b[39;49mTError(), interpolation_factors\u001b[39m=\u001b[39;49m[\u001b[39m0.0\u001b[39;49m, \u001b[39m1.0\u001b[39;49m],model_idx\u001b[39m=\u001b[39;49m[\u001b[39m16000\u001b[39;49m,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m], dataset_generator\u001b[39m=\u001b[39;49mdatagen)\n",
      "File \u001b[0;32m/system/user/publicwork/beck/projects/regularization/tflearning/tflearning/mode_connectivity/linear_interpolation.py:109\u001b[0m, in \u001b[0;36minterpolate_linear_runs\u001b[0;34m(run_0, run_1, score_fn, model_idx, interpolation_factors, interpolate_linear_kwargs, device, return_dataframe, dataset_generator)\u001b[0m\n\u001b[1;32m    105\u001b[0m     models\u001b[39m.\u001b[39mappend(m)\n\u001b[1;32m    107\u001b[0m model_0, model_1 \u001b[39m=\u001b[39m models\n\u001b[0;32m--> 109\u001b[0m idx_res_dict \u001b[39m=\u001b[39m interpolate_linear(model_0\u001b[39m=\u001b[39;49mmodel_0,\n\u001b[1;32m    110\u001b[0m                                   model_1\u001b[39m=\u001b[39;49mmodel_1,\n\u001b[1;32m    111\u001b[0m                                   score_fn\u001b[39m=\u001b[39;49mscore_fn,\n\u001b[1;32m    112\u001b[0m                                   train_dataset\u001b[39m=\u001b[39;49mds_generator\u001b[39m.\u001b[39;49mtrain_split,\n\u001b[1;32m    113\u001b[0m                                   interpolation_factors\u001b[39m=\u001b[39;49minterpolation_factors,\n\u001b[1;32m    114\u001b[0m                                   other_datasets\u001b[39m=\u001b[39;49mother_datasets,\n\u001b[1;32m    115\u001b[0m                                   \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minterpolate_linear_kwargs)\n\u001b[1;32m    116\u001b[0m res_dict[\u001b[39mtuple\u001b[39m(m_idxes)] \u001b[39m=\u001b[39m idx_res_dict\n\u001b[1;32m    117\u001b[0m \u001b[39m# convert result dict into more readable dataframe\u001b[39;00m\n",
      "File \u001b[0;32m/system/user/publicwork/beck/projects/regularization/tflearning/tflearning/mode_connectivity/linear_interpolation.py:307\u001b[0m, in \u001b[0;36minterpolate_linear\u001b[0;34m(model_0, model_1, train_dataset, score_fn, other_datasets, interpolation_factors, dataloader_kwargs, compute_model_distances, interpolation_on_train_data, update_bn_statistics, tqdm_desc)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[39m# eval on eval_datasets\u001b[39;00m\n\u001b[1;32m    306\u001b[0m     \u001b[39mfor\u001b[39;00m ds_name, dataloader \u001b[39min\u001b[39;00m eval_dataloaders\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 307\u001b[0m         score \u001b[39m=\u001b[39m eval_loop(model\u001b[39m=\u001b[39;49minterp_model, dataloader\u001b[39m=\u001b[39;49mdataloader, score_fn\u001b[39m=\u001b[39;49mscore_fn)\n\u001b[1;32m    308\u001b[0m         ds_dict[ds_name]\u001b[39m.\u001b[39mappend(score)\n\u001b[1;32m    310\u001b[0m \u001b[39mif\u001b[39;00m compute_model_distances:\n",
      "File \u001b[0;32m/system/user/publicwork/beck/projects/regularization/tflearning/tflearning/mode_connectivity/linear_interpolation.py:239\u001b[0m, in \u001b[0;36minterpolate_linear.<locals>.eval_loop\u001b[0;34m(model, dataloader, score_fn)\u001b[0m\n\u001b[1;32m    237\u001b[0m xs, ys \u001b[39m=\u001b[39m xs\u001b[39m.\u001b[39mto(device), ys\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    238\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 239\u001b[0m     y_pred \u001b[39m=\u001b[39m model(xs)\n\u001b[1;32m    240\u001b[0m     score \u001b[39m=\u001b[39m score_fn(y_pred, ys)\n\u001b[1;32m    241\u001b[0m     batch_scores\u001b[39m.\u001b[39mappend(score)\n",
      "File \u001b[0;32m/system/apps/userenv/beck/subspaces/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/system/user/publicwork/beck/projects/regularization/ml_utilities/ml_utilities/torch_models/resnet.py:84\u001b[0m, in \u001b[0;36mResnet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresnet(x)\n",
      "File \u001b[0;32m/system/apps/userenv/beck/subspaces/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/system/apps/userenv/beck/subspaces/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/system/apps/userenv/beck/subspaces/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/system/apps/userenv/beck/subspaces/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/system/apps/userenv/beck/subspaces/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/system/apps/userenv/beck/subspaces/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    169\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    170\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    173\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    177\u001b[0m     bn_training,\n\u001b[1;32m    178\u001b[0m     exponential_average_factor,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    180\u001b[0m )\n",
      "File \u001b[0;32m/system/apps/userenv/beck/subspaces/lib/python3.10/site-packages/torch/nn/functional.py:2438\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2435\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2436\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2438\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2439\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2440\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ret = interpolate_linear_runs(run_0, run_1, score_fn=TError(), interpolation_factors=[0.0, 1.0],model_idx=[16000,-1, -2], dataset_generator=datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>datasets</th>\n",
       "      <th colspan=\"3\" halign=\"left\">val</th>\n",
       "      <th colspan=\"3\" halign=\"left\">train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">interpolation_scores</th>\n",
       "      <th>instability</th>\n",
       "      <th colspan=\"2\" halign=\"left\">interpolation_scores</th>\n",
       "      <th>instability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>NaN</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <th>seeds</th>\n",
       "      <th>model_idxes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IA-A-cifar10-17.2.1-resnet-B--</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">(0, 1)</th>\n",
       "      <th>(16000, 16000)</th>\n",
       "      <td>0.180009</td>\n",
       "      <td>0.161213</td>\n",
       "      <td>0.009398</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(44500, 64000)</th>\n",
       "      <td>0.136282</td>\n",
       "      <td>0.131273</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(64001, 64001)</th>\n",
       "      <td>0.136282</td>\n",
       "      <td>0.131273</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "datasets                                                              val  \\\n",
       "score                                                interpolation_scores   \n",
       "alpha                                                                 0.0   \n",
       "job                            seeds  model_idxes                           \n",
       "IA-A-cifar10-17.2.1-resnet-B-- (0, 1) (16000, 16000)             0.180009   \n",
       "                                      (44500, 64000)             0.136282   \n",
       "                                      (64001, 64001)             0.136282   \n",
       "\n",
       "datasets                                                                    \\\n",
       "score                                                          instability   \n",
       "alpha                                                      1.0         NaN   \n",
       "job                            seeds  model_idxes                            \n",
       "IA-A-cifar10-17.2.1-resnet-B-- (0, 1) (16000, 16000)  0.161213    0.009398   \n",
       "                                      (44500, 64000)  0.131273    0.002505   \n",
       "                                      (64001, 64001)  0.131273    0.002505   \n",
       "\n",
       "datasets                                                            train  \\\n",
       "score                                                interpolation_scores   \n",
       "alpha                                                                 0.0   \n",
       "job                            seeds  model_idxes                           \n",
       "IA-A-cifar10-17.2.1-resnet-B-- (0, 1) (16000, 16000)                 0.17   \n",
       "                                      (44500, 64000)                 0.05   \n",
       "                                      (64001, 64001)                 0.05   \n",
       "\n",
       "datasets                                                                \n",
       "score                                                      instability  \n",
       "alpha                                                  1.0         NaN  \n",
       "job                            seeds  model_idxes                       \n",
       "IA-A-cifar10-17.2.1-resnet-B-- (0, 1) (16000, 16000)  0.12       0.025  \n",
       "                                      (44500, 64000)  0.05       0.000  \n",
       "                                      (64001, 64001)  0.05       0.000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64001, 44500)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_0.highest_model_idx, run_0.best_model_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64001, 64000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_1.highest_model_idx, run_1.best_model_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subspaces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac019f01eb2a0970f066d5e193a84f30bb43215eeeface9d3d8db32241c79700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
